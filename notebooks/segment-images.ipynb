{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If Dockerfiles have not been modified, connect to the Jupyter server with:  \n",
    "- ```http://localhost:8011/tree?token=segment-images-cpu``` to run Torch on CPU  \n",
    "\n",
    "This notebook describes a pipeline to semantically segment an image with the [OpenMMLab Semantic Segmentation Toolbox and Benchmark](https://github.com/open-mmlab/mmsegmentation).  It takes an input image and saves (1) the inference of the class of each pixel as a ```.json```, (2) a dictionary of classes and their corresponding id as a ```.json```, and (3) a visualisation of the segmented image as a ```.jpg```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_dir = \"data\"\n",
    "input_dir = \"place-pulse-singapore-panos-512-1024\"\n",
    "segmentation_dir = \"place-pulse-singapore-segmented-512-1024\"\n",
    "visualisaion_dir = \"place-pulse-singapore-segmented-visualised-512-1024\"\n",
    "checkpoint_link = \"https://download.openmmlab.com/mmsegmentation/v0.5/fcn/fcn_d6_r101-d16_512x1024_80k_cityscapes/fcn_d6_r101-d16_512x1024_80k_cityscapes_20210308_102747-cb336445.pth\"\n",
    "config_file = \"./configs/fcn/fcn-d6_r101-d16_4xb2-80k_cityscapes-512x1024.py\"\n",
    "checkpoint_file = \"./fcn_d6_r101-d16_512x1024_80k_cityscapes_20210308_102747-cb336445.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmseg.apis import inference_model, init_model, show_result_pyplot\n",
    "import mmcv\n",
    "import numpy as np\n",
    "\n",
    "import json\n",
    "import os\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget {checkpoint_link}\n",
    "model = init_model(config_file, checkpoint_file, device=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_path = []\n",
    "for dirpath, dirnames, filenames in os.walk(os.path.join(target_dir, input_dir)):\n",
    "    images_path.extend(filenames)\n",
    "    break\n",
    "images_id = {}\n",
    "for image_path in images_path:\n",
    "    images_id['.'.join(image_path.split('.')[:-1])] = os.path.join(target_dir, input_dir, image_path)\n",
    "\n",
    "Path(os.path.join(target_dir, segmentation_dir)).mkdir(parents=True, exist_ok=True)\n",
    "Path(os.path.join(target_dir, visualisaion_dir)).mkdir(parents=True, exist_ok=True)\n",
    "with open(os.path.join(target_dir, \"classes.json\"), 'w') as fp:\n",
    "    json.dump({index: class_name for index, class_name in enumerate(model.dataset_meta[\"classes\"])}, fp)\n",
    "for id, path in images_id.items():\n",
    "    if Path(os.path.join(target_dir, segmentation_dir, f\"{id}.json\")).is_file():\n",
    "        continue\n",
    "    image = mmcv.imread(path)\n",
    "    result = inference_model(model, image)\n",
    "    output = np.argmax(result.seg_logits.data, axis=0).tolist()\n",
    "    with open(os.path.join(target_dir, segmentation_dir, f\"{id}.json\"), 'w') as fp:\n",
    "        json.dump(output, fp)\n",
    "    show_result_pyplot(model, image, result, show=True, out_file=os.path.join(target_dir, visualisaion_dir, f\"{id}.jpg\"), opacity=0.5)  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
