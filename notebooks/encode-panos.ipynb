{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If Dockerfiles have not been modified, connect to the Jupyter server with ```http://localhost:8006/tree?token=encode-panos```  \n",
    "\n",
    "This notebook describes a pipeline to encode panoramas as described in Naik et al (2014).  \n",
    "It takes:\n",
    "- a base image as a ```.jpg```;\n",
    "- its GIST descriptor as a ```.csv```;\n",
    "- its textonmap as a ```.png```;\n",
    "- its segmentations by ground, sky, vertical, and porous as ```.pgm```s; and  \n",
    "returns a 5944×1 matrix as a ```.json``` encoding the image information.  \n",
    "\n",
    "More specifically:\n",
    "1. Each segmentation is converted into a 256×512 matrix of weights;\n",
    "2. The segmentation weights are used to weight the histograms of the textonmap and base image, yielding 4 (for each segmentation) 8×8×8 histograms from the textonmap, and 4 14×4×4 histograms from the base image (an RGB to CIELAB colour conversion is first performed);\n",
    "3. Flattening the 3000×1 GIST discriptor with 4 8×8×8 matrices and 4 14×4×4 matrices yields a 5944×1 matrix.  \n",
    "\n",
    "> N. Naik, J. Philipoom, R. Raskar and C. Hidalgo, \"Streetscore -- Predicting the Perceived Safety of One Million Streetscapes,\" 2014 IEEE Conference on Computer Vision and Pattern Recognition Workshops, Columbus, OH, USA, 2014, pp. 793-799, doi: 10.1109/CVPRW.2014.121."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_dir = \"data\"\n",
    "image_dir = \"shunfu-panos\"\n",
    "gist_dir = \"shunfu-gists\"\n",
    "textonmap_dir = \"shunfu-textonmaps\"\n",
    "segmentation_dir = \"shunfu-segmentations\"\n",
    "output_dir = \"shunfu-panos-encoded\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "\n",
    "import csv\n",
    "import json\n",
    "import os\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_path = []\n",
    "for dirpath, dirnames, filenames in os.walk(os.path.join(target_dir, image_dir)):\n",
    "    images_path.extend(filenames)\n",
    "    break\n",
    "images_id = {}\n",
    "for image_path in images_path:\n",
    "   images_id['.'.join(image_path.split('.')[:-1])] = os.path.join(target_dir, image_dir, image_path)\n",
    "images_df = pd.DataFrame.from_dict(images_id, orient=\"index\", columns=[\"fp\"])\n",
    "\n",
    "gists_path = []\n",
    "for dirpath, dirnames, filenames in os.walk(os.path.join(target_dir, gist_dir)):\n",
    "    gists_path.extend(filenames)\n",
    "    break\n",
    "gists_id = {}\n",
    "for gist_path in gists_path:\n",
    "   gists_id['.'.join(gist_path.split('.')[:-1])] = os.path.join(target_dir, gist_dir, gist_path)\n",
    "gists_df = pd.DataFrame.from_dict(gists_id, orient=\"index\", columns=[\"fp\"])\n",
    "\n",
    "textonmaps_path = []\n",
    "for dirpath, dirnames, filenames in os.walk(os.path.join(target_dir, textonmap_dir)):\n",
    "    textonmaps_path.extend(filenames)\n",
    "    break\n",
    "textonmaps_id = {}\n",
    "for textonmap_path in textonmaps_path:\n",
    "   textonmaps_id['.'.join(textonmap_path.split('.')[:-1])] = os.path.join(target_dir, textonmap_dir, textonmap_path)\n",
    "textonmaps_df = pd.DataFrame.from_dict(textonmaps_id, orient=\"index\", columns=[\"fp\"])\n",
    "\n",
    "segmentations_path = []\n",
    "for dirpath, dirnames, filenames in os.walk(os.path.join(target_dir, segmentation_dir)):\n",
    "    segmentations_path.extend(filenames)\n",
    "    break\n",
    "grounds_id = {}\n",
    "verticals_id = {}\n",
    "porouss_id = {}\n",
    "skys_id = {}\n",
    "for segmentation_path in segmentations_path:\n",
    "    segmentation_type = segmentation_path.split('.')[1]\n",
    "    if segmentation_type == \"v000\":\n",
    "        grounds_id['.'.join(segmentation_path.split('.')[:-2])] = os.path.join(target_dir, segmentation_dir, segmentation_path)\n",
    "    elif segmentation_type == \"v090\":\n",
    "        verticals_id['.'.join(segmentation_path.split('.')[:-2])] = os.path.join(target_dir, segmentation_dir, segmentation_path)\n",
    "    elif segmentation_type == \"hpor\":\n",
    "        porouss_id['.'.join(segmentation_path.split('.')[:-2])] = os.path.join(target_dir, segmentation_dir, segmentation_path)\n",
    "    elif segmentation_type == \"vsky\":\n",
    "        skys_id['.'.join(segmentation_path.split('.')[:-2])] = os.path.join(target_dir, segmentation_dir, segmentation_path)\n",
    "grounds_df = pd.DataFrame.from_dict(grounds_id, orient=\"index\", columns=[\"fp\"])\n",
    "verticals_df = pd.DataFrame.from_dict(verticals_id, orient=\"index\", columns=[\"fp\"])\n",
    "porouss_df = pd.DataFrame.from_dict(porouss_id, orient=\"index\", columns=[\"fp\"])\n",
    "skys_df = pd.DataFrame.from_dict(skys_id, orient=\"index\", columns=[\"fp\"])\n",
    "\n",
    "ids_df = images_df.join(\n",
    "    gists_df, how=\"inner\", lsuffix=\"_images\", rsuffix=\"_gists\").join(\n",
    "        textonmaps_df, how=\"inner\").join(\n",
    "            grounds_df, how=\"inner\", lsuffix=\"_textonmaps\", rsuffix=\"_grounds\").join(\n",
    "                verticals_df, how=\"inner\").join(\n",
    "                    porouss_df, how=\"inner\", lsuffix=\"_verticals\", rsuffix=\"_porouss\").join(\n",
    "                        skys_df, how=\"inner\").rename(columns={\"fp\": \"fp_skys\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Path(os.path.join(target_dir, output_dir)).mkdir(parents=True, exist_ok=True)\n",
    "count = 0\n",
    "for index, row in ids_df.iterrows():\n",
    "    try:\n",
    "        image = cv2.imread(row[\"fp_images\"], cv2.IMREAD_COLOR)\n",
    "        gist = []\n",
    "        with open(row[\"fp_gists\"], 'r') as fp:\n",
    "            csv_reader = csv.reader(fp)\n",
    "            for line in csv_reader:\n",
    "                if line:\n",
    "                    gist.append(float(line[0]))\n",
    "        area = sum(gist)\n",
    "        gist = [x / area for x in gist]\n",
    "        textonmap = cv2.imread(row[\"fp_textonmaps\"], cv2.IMREAD_COLOR)\n",
    "        ground = cv2.imread(row[\"fp_grounds\"], cv2.IMREAD_GRAYSCALE)\n",
    "        vertical = cv2.imread(row[\"fp_verticals\"], cv2.IMREAD_GRAYSCALE)\n",
    "        porous = cv2.imread(row[\"fp_porouss\"], cv2.IMREAD_GRAYSCALE)\n",
    "        sky = cv2.imread(row[\"fp_skys\"], cv2.IMREAD_GRAYSCALE)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        continue\n",
    "\n",
    "    image = cv2.cvtColor(cv2.resize(image, (512, 256)), cv2.COLOR_BGR2LAB)\n",
    "    textonmap = cv2.cvtColor(cv2.resize(textonmap, (512, 256)), cv2.COLOR_BGR2RGB)\n",
    "    ground = cv2.resize(ground, (512, 256)).astype(float) / 255 * 100\n",
    "    vertical = cv2.resize(vertical, (512, 256)).astype(float) / 255 * 100\n",
    "    porous = cv2.resize(porous, (512, 256)).astype(float) / 255 * 100\n",
    "    sky = cv2.resize(sky, (512, 256)).astype(float) / 255 * 100\n",
    "\n",
    "    ground_texton_histogram, e = np.histogramdd(textonmap.reshape(256 * 512, 3), bins=[8, 8, 8], range=[(0, 256), (0, 256), (0, 256)], density=True, weights=ground.reshape(256 * 512))\n",
    "    vertical_texton_histogram, e = np.histogramdd(textonmap.reshape(256 * 512, 3), bins=[8, 8, 8], range=[(0, 256), (0, 256), (0, 256)], density=True, weights=vertical.reshape(256 * 512))\n",
    "    porous_texton_histogram, e = np.histogramdd(textonmap.reshape(256 * 512, 3), bins=[8, 8, 8], range=[(0, 256), (0, 256), (0, 256)], density=True, weights=porous.reshape(256 * 512))\n",
    "    sky_texton_histogram, e = np.histogramdd(textonmap.reshape(256 * 512, 3), bins=[8, 8, 8], range=[(0, 256), (0, 256), (0, 256)], density=True, weights=sky.reshape(256 * 512))\n",
    "    ground_colour_histogram, e = np.histogramdd(image.reshape(256 * 512, 3), bins=[14, 4, 4], range=[(0, 256), (0, 256), (0, 256)], density=True, weights=ground.reshape(256 * 512))\n",
    "    vertical_colour_histogram, e = np.histogramdd(image.reshape(256 * 512, 3), bins=[14, 4, 4], range=[(0, 256), (0, 256), (0, 256)], density=True, weights=vertical.reshape(256 * 512))\n",
    "    porous_colour_histogram, e = np.histogramdd(image.reshape(256 * 512, 3), bins=[14, 4, 4], range=[(0, 256), (0, 256), (0, 256)], density=True, weights=porous.reshape(256 * 512))\n",
    "    sky_colour_histogram, e = np.histogramdd(image.reshape(256 * 512, 3), bins=[14, 4, 4], range=[(0, 256), (0, 256), (0, 256)], density=True, weights=sky.reshape(256 * 512))\n",
    "\n",
    "    image_embedding = np.array(ground_texton_histogram).flatten().tolist()\\\n",
    "            + np.array(vertical_texton_histogram).flatten().tolist()\\\n",
    "            + np.array(porous_texton_histogram).flatten().tolist()\\\n",
    "            + np.array(sky_texton_histogram).flatten().tolist()\\\n",
    "        + gist\\\n",
    "        + np.array(ground_colour_histogram).flatten().tolist()\\\n",
    "            + np.array(vertical_colour_histogram).flatten().tolist()\\\n",
    "            + np.array(porous_colour_histogram).flatten().tolist()\\\n",
    "            + np.array(sky_colour_histogram).flatten().tolist()\n",
    "\n",
    "    with open(os.path.join(target_dir, output_dir, index + \".json\"), 'w') as fp:\n",
    "        json.dump(image_embedding, fp)\n",
    "\n",
    "    count += 1\n",
    "    if not count % 50:\n",
    "        print(count)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
