{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If Dockerfiles have not been modified, connect to the Jupyter server with ```http://localhost:8007/tree?token=encode-images```  \n",
    "\n",
    "This notebook describes a pipeline to encode panoramas derived from Naik et al (2014).  \n",
    "It takes:\n",
    "- a base image as a ```.jpg```;\n",
    "- its GIST descriptor as a ```.csv```;\n",
    "- its textonmap as a ```.png```; and\n",
    "returns a 3736×1 matrix as a ```.json``` encoding the image information.  \n",
    "\n",
    "More specifically:\n",
    "1. The RGB histogram of the textonmap is calculated yielding a 8×8×8 histogram;\n",
    "2. The CIELAB historgram of the base image is calculated yielding a 14×4×4 histogram;\n",
    "3. Flattening the 3000×1 GIST discriptor with a 8×8×8 matrix and a 14×4×4 matrix yields a 3736×1 matrix.  \n",
    "\n",
    "> N. Naik, J. Philipoom, R. Raskar and C. Hidalgo, \"Streetscore -- Predicting the Perceived Safety of One Million Streetscapes,\" 2014 IEEE Conference on Computer Vision and Pattern Recognition Workshops, Columbus, OH, USA, 2014, pp. 793-799, doi: 10.1109/CVPRW.2014.121."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_dir = \"data\"\n",
    "image_dir = \"shunfu-panos\"\n",
    "gist_dir = \"shunfu-gists\"\n",
    "textonmap_dir = \"shunfu-textonmaps\"\n",
    "output_dir = \"shunfu-panos-encoded\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "\n",
    "import csv\n",
    "import json\n",
    "import os\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_path = []\n",
    "for dirpath, dirnames, filenames in os.walk(os.path.join(target_dir, image_dir)):\n",
    "    images_path.extend(filenames)\n",
    "    break\n",
    "images_id = {}\n",
    "for image_path in images_path:\n",
    "   images_id['.'.join(image_path.split('.')[:-1])] = os.path.join(target_dir, image_dir, image_path)\n",
    "images_df = pd.DataFrame.from_dict(images_id, orient=\"index\", columns=[\"fp\"])\n",
    "\n",
    "gists_path = []\n",
    "for dirpath, dirnames, filenames in os.walk(os.path.join(target_dir, gist_dir)):\n",
    "    gists_path.extend(filenames)\n",
    "    break\n",
    "gists_id = {}\n",
    "for gist_path in gists_path:\n",
    "   gists_id['.'.join(gist_path.split('.')[:-1])] = os.path.join(target_dir, gist_dir, gist_path)\n",
    "gists_df = pd.DataFrame.from_dict(gists_id, orient=\"index\", columns=[\"fp\"])\n",
    "\n",
    "textonmaps_path = []\n",
    "for dirpath, dirnames, filenames in os.walk(os.path.join(target_dir, textonmap_dir)):\n",
    "    textonmaps_path.extend(filenames)\n",
    "    break\n",
    "textonmaps_id = {}\n",
    "for textonmap_path in textonmaps_path:\n",
    "   textonmaps_id['.'.join(textonmap_path.split('.')[:-1])] = os.path.join(target_dir, textonmap_dir, textonmap_path)\n",
    "textonmaps_df = pd.DataFrame.from_dict(textonmaps_id, orient=\"index\", columns=[\"fp\"])\n",
    "\n",
    "ids_df = images_df.join(\n",
    "    gists_df, how=\"inner\", lsuffix=\"_images\", rsuffix=\"_gists\").join(\n",
    "        textonmaps_df, how=\"inner\")..rename(columns={\"fp\": \"fp_textonmaps\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Path(os.path.join(target_dir, output_dir)).mkdir(parents=True, exist_ok=True)\n",
    "count = 0\n",
    "for index, row in ids_df.iterrows():\n",
    "    try:\n",
    "        image = cv2.imread(row[\"fp_images\"], cv2.IMREAD_COLOR)\n",
    "        gist = []\n",
    "        with open(row[\"fp_gists\"], 'r') as fp:\n",
    "            csv_reader = csv.reader(fp)\n",
    "            for line in csv_reader:\n",
    "                if line:\n",
    "                    gist.append(float(line[0]))\n",
    "        area = sum(gist)\n",
    "        gist = [x / area for x in gist]\n",
    "        textonmap = cv2.imread(row[\"fp_textonmaps\"], cv2.IMREAD_COLOR)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        continue\n",
    "\n",
    "    image = cv2.cvtColor(cv2.resize(image, (512, 256)), cv2.COLOR_BGR2LAB)\n",
    "    textonmap = cv2.cvtColor(cv2.resize(textonmap, (512, 256)), cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    texton_histogram, e = np.histogramdd(textonmap.reshape(256 * 512, 3), bins=[8, 8, 8], range=[(0, 256), (0, 256), (0, 256)])\n",
    "    colour_histogram, e = np.histogramdd(image.reshape(256 * 512, 3), bins=[14, 4, 4], range=[(0, 256), (0, 256), (0, 256)])\n",
    "\n",
    "    image_embedding = np.array(texton_histogram).flatten().tolist()+ gist + np.array(colour_histogram).flatten().tolist()\n",
    "\n",
    "    with open(os.path.join(target_dir, output_dir, index + \".json\"), 'w') as fp:\n",
    "        json.dump(image_embedding, fp)\n",
    "\n",
    "    count += 1\n",
    "    if not count % 50:\n",
    "        print(count)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
